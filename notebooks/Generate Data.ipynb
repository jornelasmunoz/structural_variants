{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c6d3e2-b74b-4a48-9d91-06d3a363639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Show matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313f40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/Users/jocelynornelasmunoz/Desktop/structural_variants/lib')\n",
    "import generate_data as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "import sympy\n",
    "import random\n",
    "\n",
    "# MATLAB\n",
    "# import matlab.engine\n",
    "# import matlab\n",
    "# print(matlab.__file__)\n",
    "# eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebb744-af6a-4277-93fe-70d2eb0062c5",
   "metadata": {},
   "source": [
    "# Generate data and save to `.mat` file\n",
    "1. Define the set of parameters\n",
    "2. Generate diploid data\n",
    "3. Save to `.mat` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29705b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 4,\n",
    "    'pctNovel': 0.02,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2afcde2-34b1-45df-921e-266b34f60fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ('/Users/jocelynornelasmunoz/Desktop/structural_variants/data/simulated/%ip_%ic_coverage/')%(params['lambda_p'],params['lambda_c'])\n",
    "if not os.path.exists(data_path): os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9daa7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using parameters:\n",
      "\t r :  1\n",
      "\t n :  100\n",
      "\t k :  10\n",
      "\t lambda_c :  4\n",
      "\t lambda_p :  4\n",
      "\t pctNovel :  0.02\n",
      "\t erreps :  0.01\n",
      "\t pct_similarity :  0.5\n",
      "CPU times: user 4.03 ms, sys: 1.13 ms, total: 5.17 ms\n",
      "Wall time: 4.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = gd.generate_diploid_data(params)\n",
    "savemat((data_path + '%.2fpctNovel.mat')%(params['pctNovel']) , data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5404df9e-97f7-4069-9ef3-cb043d136355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['f_p2', 'f_c', 'f_p', 'z_p', 'y_p', 'f_h', 'z_h', 'y_h', 'f_n', 'z_n', 'y_n', 'A_zp', 'A_yp', 'mu_p', 'var_p', 's_p', 'A_zc', 'A_yc', 'mu_c', 'var_c', 's_c', 'r', 'n', 'k', 'lambda_c', 'lambda_p', 'pctNovel', 'erreps', 'pct_similarity'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a2031-df50-43d6-9db4-c006de308164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060359b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Defining generate data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904813f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_haploid_data(params):\n",
    "    '''\n",
    "    Generate simulated data for a one parent, one child Structural Variant analysis\n",
    "    Args: A dictionary containing the following parameters as keys\n",
    "        n: size of data vectors (signals)\n",
    "        k: total number of structural variants\n",
    "        pctNovel: percent of novel structural variants in [0,1] (biological reality- very small %)\n",
    "        lambda_p, lambda_c: sequence coverage of child and parent, respectively\n",
    "        erreps: error (>0) incurred by sequencing and mapping process\n",
    "        r: dispersion parameter for Negative Binomial distribution\n",
    "    \n",
    "    Output: A dictionary containing the following data elements as keys\n",
    "        A_c: (lambda_c - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        A_p: (lambda_p - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        mu_p, var_p: Mean and variance sequence coverage for parent; mu_p = A_p * f_p \n",
    "        mu_c, var_c: Mean and variance sequence coverage for child;  mu_c = A_c * f_c \n",
    "        s_p: nx1 random vector drawn from Negative binomial distribution (for parent)\n",
    "        s_c: nx1 random vector drawn from Negative binomial distribution (for child)\n",
    "        TODO: add mu and var\n",
    "        for i in {P (parent), H (inherited), N (novel)}:\n",
    "        z_i: nx1 indicator vector of homogeneous structural variants\n",
    "        y_i: nx1 indicator vector of heterogeneous structural variants\n",
    "        \n",
    "    '''\n",
    "    q = np.random.permutation(params['n'])\n",
    "    #print(q)\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "\n",
    "    f_p, f_c, f_h, f_n = np.zeros((params['n'],1), dtype=np.int8),np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8)\n",
    "    f_p[q[: params['k']]], f_c[q[startVal:endVal]] = 1,1\n",
    "    f_h[q[startVal:params['k']+1]], f_n[q[params['k']+1:endVal]] = 1,1\n",
    "    \n",
    "    \n",
    "    d = {}\n",
    "    d['f_p'] = f_p; d['f_h'] = f_h; d['f_n'] = f_n; d['f_c'] = f_h + f_n; \n",
    "    \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b593fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 8,\n",
    "    'pctNovel': 0.15,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diploid_data(params):\n",
    "    q = np.random.permutation(params['n'])\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "    similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "    signals = ['f_p2', 'f_c']\n",
    "    for i,letter in enumerate(['p', 'h', 'n']):\n",
    "        signals.append('f_%s'%letter)\n",
    "        signals.append('z_%s'%letter)\n",
    "        signals.append('y_%s'%letter)\n",
    "\n",
    "    # Initialize signals\n",
    "    d= {}\n",
    "    for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "\n",
    "    # parent signals: \n",
    "    #        f_p  - k elements will be 1s and 2s randomly selected\n",
    "    #        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "    for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "    d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "    d['f_p2'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "\n",
    "    # child signal\n",
    "    #     inherited\n",
    "    for i in np.arange(d['f_p'].shape[0]):\n",
    "        if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_c'][i]= 2\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,3)\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_c'][i]= 1\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_c'][i]= np.random.randint(1,3)\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,2)\n",
    "        \n",
    "    #     novel        \n",
    "    d['f_n'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "    d['f_c'] = d['f_h'] +d ['f_n']\n",
    "    \n",
    "    # convert signals to indicators\n",
    "    for j,letter in enumerate(['p','h','n']):\n",
    "        for i in np.arange(d['f_c'].shape[0]):\n",
    "            if   d['f_%s'%letter][i]==2: d['z_%s'%letter][i]=1\n",
    "            elif d['f_%s'%letter][i]==1: d['y_%s'%letter][i]=1\n",
    "            \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params['lambda_%s'%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9038e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap = generate_haploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123300fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da513da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,letter in enumerate(['p','h','n']):\n",
    "    print('f_%s: \\n'%letter,np.transpose(d['f_%s'%letter]))\n",
    "    print('z_%s: \\n'%letter,np.transpose(d['z_%s'%letter]))\n",
    "    print('y_%s: \\n'%letter,np.transpose(d['y_%s'%letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2809b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = generate_diploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'] - data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1b590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
