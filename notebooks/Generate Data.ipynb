{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5c2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Show matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9267a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/Users/jocelynornelasmunoz/Desktop/structural_variants/lib')\n",
    "sys.path.insert(0, '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/structural_variants/lib')\n",
    "import generate_data as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "import sympy\n",
    "import random\n",
    "\n",
    "# MATLAB\n",
    "# import matlab.engine\n",
    "# import matlab\n",
    "# print(matlab.__file__)\n",
    "# eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65c340",
   "metadata": {},
   "source": [
    "# Generate data and save to `.mat` file\n",
    "1. Define the set of parameters\n",
    "2. Generate diploid data\n",
    "3. Save to `.mat` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3090f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 4,\n",
    "    'pctNovel': 0.02,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762c46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_path = '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/structural_variants/data/simulated/'\n",
    "desktop_path = '/Users/jocelynornelasmunoz/Desktop/structural_variants/data/simulated/'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fccbd8b-f471-4fa9-a7e2-0d9187aa0dcc",
   "metadata": {},
   "source": [
    "data_path = (desktop_path+'%ip_%ic_coverage/')%(params['lambda_p'],params['lambda_c'])\n",
    "if not os.path.exists(data_path): os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e5d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using parameters:\n",
      "\t r :  1\n",
      "\t n :  100\n",
      "\t k :  10\n",
      "\t lambda_c :  4\n",
      "\t lambda_p :  4\n",
      "\t pctNovel :  0.02\n",
      "\t erreps :  0.01\n",
      "\t pct_similarity :  0.5\n",
      "CPU times: user 7.64 ms, sys: 3.04 ms, total: 10.7 ms\n",
      "Wall time: 9.64 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = gd.generate_diploid_data(params)\n",
    "savemat((desktop_path + '%i_%ipctNovel.mat')%(params['n'],params['pctNovel']*100) , data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b47e927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['f_p2', 'f_c', 'f_p', 'z_p', 'y_p', 'f_h', 'z_h', 'y_h', 'f_n', 'z_n', 'y_n', 'A_zp', 'A_yp', 'mu_p', 'var_p', 's_p', 'A_zc', 'A_yc', 'mu_c', 'var_c', 's_c', 'r', 'n', 'k', 'lambda_c', 'lambda_p', 'pctNovel', 'erreps', 'pct_similarity'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4350d19-16db-40d2-9714-892d37e12685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(data['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260a1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['f_c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a2677-1291-4e87-aa0e-58e064c09b4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Debug `generate_diploid_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac780f-5250-49ac-ad59-7c8b0bbd632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.permutation(params['n'])\n",
    "startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "signals = ['f_p2', 'f_c']\n",
    "for i,letter in enumerate(['p', 'h', 'n']):\n",
    "    signals.append('f_%s'%letter)\n",
    "    signals.append('z_%s'%letter)\n",
    "    signals.append('y_%s'%letter)\n",
    "\n",
    "# Initialize signals\n",
    "d= {}\n",
    "for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae320ef9-d416-4be4-b23b-5987fff8efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent signals: \n",
    "#        f_p  - k elements will be 1s and 2s randomly selected\n",
    "#        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "d['f_p2'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e391c5-fab4-43cb-9308-ac93ba766e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d['f_p'][q[0:similarity]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632df2f7-6a79-4e23-88f4-257916095c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d['f_p2'][q[0:similarity]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd896728-d729-401c-89cc-c78cdd99f3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.nonzero(d['f_p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb55ae-7f5b-4b71-a104-d26e50e03c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0:similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e89c18-6881-4a7f-a174-ffb66e0d04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child signal\n",
    "#     inherited\n",
    "for i in np.arange(d['f_p'].shape[0]):\n",
    "    if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_h'][i]= 2\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,3)\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_h'][i]= 1\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_h'][i]= np.random.randint(1,3)\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ad9bf-5e17-47ae-b254-e8afbc0c5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42130f94-6f9a-4662-8332-e10d1d01d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     novel        \n",
    "d['f_n'][random.choices(q, k=int(params['k']*params['pctNovel']))]= np.random.randint(1,3) \n",
    "d['f_c'] = d['f_h'] +d ['f_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837c60e-e1fe-43f3-b3d5-7928bb15b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefb2a0-fe87-4333-9d7b-f389d35d6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff29b2-390f-4b5e-a8cc-7882dcd1a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d8e2e-f395-412b-b1e4-3b6a9cec8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9ce28-9bd0-49ea-9afc-e7fb0cdc0c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67641b96-6028-4a3f-b58c-230f12e199bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert signals to indicators\n",
    "for j,letter in enumerate(['p','h','n']):\n",
    "    for i in np.arange(d['f_c'].shape[0]):\n",
    "        if   d['f_%s'%letter][i]==2: d['z_%s'%letter][i]=1\n",
    "        elif d['f_%s'%letter][i]==1: d['y_%s'%letter][i]=1\n",
    "\n",
    "for i, letter in enumerate(['p','c']):\n",
    "    d['A_z%s'%letter]   = (2*params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "    d['A_y%s'%letter]   = (params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "    d['mu_%s'%letter]  = np.matmul((d['A_z%s'%letter]+d['A_y%s'%letter]).toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "    d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "    d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "\n",
    "data = {**d, **params}\n",
    "print()\n",
    "print('Using parameters:')\n",
    "for key, val in params.items():\n",
    "    print('\\t', key, ': ', val)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad62bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Defining generate data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a4f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_haploid_data(params):\n",
    "    '''\n",
    "    Generate simulated data for a one parent, one child Structural Variant analysis\n",
    "    Args: A dictionary containing the following parameters as keys\n",
    "        n: size of data vectors (signals)\n",
    "        k: total number of structural variants\n",
    "        pctNovel: percent of novel structural variants in [0,1] (biological reality- very small %)\n",
    "        lambda_p, lambda_c: sequence coverage of child and parent, respectively\n",
    "        erreps: error (>0) incurred by sequencing and mapping process\n",
    "        r: dispersion parameter for Negative Binomial distribution\n",
    "    \n",
    "    Output: A dictionary containing the following data elements as keys\n",
    "        A_c: (lambda_c - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        A_p: (lambda_p - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        mu_p, var_p: Mean and variance sequence coverage for parent; mu_p = A_p * f_p \n",
    "        mu_c, var_c: Mean and variance sequence coverage for child;  mu_c = A_c * f_c \n",
    "        s_p: nx1 random vector drawn from Negative binomial distribution (for parent)\n",
    "        s_c: nx1 random vector drawn from Negative binomial distribution (for child)\n",
    "        TODO: add mu and var\n",
    "        for i in {P (parent), H (inherited), N (novel)}:\n",
    "        z_i: nx1 indicator vector of homogeneous structural variants\n",
    "        y_i: nx1 indicator vector of heterogeneous structural variants\n",
    "        \n",
    "    '''\n",
    "    q = np.random.permutation(params['n'])\n",
    "    #print(q)\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "\n",
    "    f_p, f_c, f_h, f_n = np.zeros((params['n'],1), dtype=np.int8),np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8)\n",
    "    f_p[q[: params['k']]], f_c[q[startVal:endVal]] = 1,1\n",
    "    f_h[q[startVal:params['k']+1]], f_n[q[params['k']+1:endVal]] = 1,1\n",
    "    \n",
    "    \n",
    "    d = {}\n",
    "    d['f_p'] = f_p; d['f_h'] = f_h; d['f_n'] = f_n; d['f_c'] = f_h + f_n; \n",
    "    \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 8,\n",
    "    'pctNovel': 0.15,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diploid_data(params):\n",
    "    q = np.random.permutation(params['n'])\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "    similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "    signals = ['f_p2', 'f_c']\n",
    "    for i,letter in enumerate(['p', 'h', 'n']):\n",
    "        signals.append('f_%s'%letter)\n",
    "        signals.append('z_%s'%letter)\n",
    "        signals.append('y_%s'%letter)\n",
    "\n",
    "    # Initialize signals\n",
    "    d= {}\n",
    "    for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "\n",
    "    # parent signals: \n",
    "    #        f_p  - k elements will be 1s and 2s randomly selected\n",
    "    #        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "    for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "    d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "    d['f_p2'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "\n",
    "    # child signal\n",
    "    #     inherited\n",
    "    for i in np.arange(d['f_p'].shape[0]):\n",
    "        if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_c'][i]= 2\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,3)\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_c'][i]= 1\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_c'][i]= np.random.randint(1,3)\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,2)\n",
    "        \n",
    "    #     novel        \n",
    "    d['f_n'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "    d['f_c'] = d['f_h'] +d ['f_n']\n",
    "    \n",
    "    # convert signals to indicators\n",
    "    for j,letter in enumerate(['p','h','n']):\n",
    "        for i in np.arange(d['f_c'].shape[0]):\n",
    "            if   d['f_%s'%letter][i]==2: d['z_%s'%letter][i]=1\n",
    "            elif d['f_%s'%letter][i]==1: d['y_%s'%letter][i]=1\n",
    "            \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params['lambda_%s'%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap = generate_haploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d782a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c7e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,letter in enumerate(['p','h','n']):\n",
    "    print('f_%s: \\n'%letter,np.transpose(d['f_%s'%letter]))\n",
    "    print('z_%s: \\n'%letter,np.transpose(d['z_%s'%letter]))\n",
    "    print('y_%s: \\n'%letter,np.transpose(d['y_%s'%letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = generate_diploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f63e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'] - data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c3f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
