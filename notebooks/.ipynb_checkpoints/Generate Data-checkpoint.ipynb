{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'generate_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8bed826cb129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# MATLAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'generate_data'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, 'structural_variants/lib/')\n",
    "import generate_data as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "import sympy\n",
    "import random\n",
    "\n",
    "\n",
    "# MATLAB\n",
    "# import matlab.engine\n",
    "# import matlab\n",
    "# print(matlab.__file__)\n",
    "# eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining generate data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_haploid_data(params):\n",
    "    '''\n",
    "    Generate simulated data for a one parent, one child Structural Variant analysis\n",
    "    Args: A dictionary containing the following parameters as keys\n",
    "        n: size of data vectors (signals)\n",
    "        k: total number of structural variants\n",
    "        pctNovel: percent of novel structural variants in [0,1] (biological reality- very small %)\n",
    "        lambda_p, lambda_c: sequence coverage of child and parent, respectively\n",
    "        erreps: error (>0) incurred by sequencing and mapping process\n",
    "        r: dispersion parameter for Negative Binomial distribution\n",
    "    \n",
    "    Output: A dictionary containing the following data elements as keys\n",
    "        A_c: (lambda_c - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        A_p: (lambda_p - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        mu_p, var_p: Mean and variance sequence coverage for parent; mu_p = A_p * f_p \n",
    "        mu_c, var_c: Mean and variance sequence coverage for child;  mu_c = A_c * f_c \n",
    "        s_p: nx1 random vector drawn from Negative binomial distribution (for parent)\n",
    "        s_c: nx1 random vector drawn from Negative binomial distribution (for child)\n",
    "        TODO: add mu and var\n",
    "        for i in {P (parent), H (inherited), N (novel)}:\n",
    "        z_i: nx1 indicator vector of homogeneous structural variants\n",
    "        y_i: nx1 indicator vector of heterogeneous structural variants\n",
    "        \n",
    "    '''\n",
    "    q = np.random.permutation(params['n'])\n",
    "    #print(q)\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "\n",
    "    f_p, f_c, f_h, f_n = np.zeros((params['n'],1), dtype=np.int8),np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8)\n",
    "    f_p[q[: params['k']]], f_c[q[startVal:endVal]] = 1,1\n",
    "    f_h[q[startVal:params['k']+1]], f_n[q[params['k']+1:endVal]] = 1,1\n",
    "    \n",
    "    \n",
    "    d = {}\n",
    "    d['f_p'] = f_p; d['f_h'] = f_h; d['f_n'] = f_n; d['f_c'] = f_h + f_n; \n",
    "    \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 8,\n",
    "    'pctNovel': 0.15,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diploid_data(params):\n",
    "    q = np.random.permutation(params['n'])\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "    similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "    signals = ['f_p2', 'f_c']\n",
    "    for i,letter in enumerate(['p', 'h', 'n']):\n",
    "        signals.append('f_%s'%letter)\n",
    "        signals.append('z_%s'%letter)\n",
    "        signals.append('y_%s'%letter)\n",
    "\n",
    "    # Initialize signals\n",
    "    d= {}\n",
    "    for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "\n",
    "    # parent signals: \n",
    "    #        f_p  - k elements will be 1s and 2s randomly selected\n",
    "    #        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "    for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "    d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "    d['f_p2'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "\n",
    "    # child signal\n",
    "    #     inherited\n",
    "    for i in np.arange(d['f_p'].shape[0]):\n",
    "        if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_c'][i]= 2\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,3)\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_c'][i]= 1\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_c'][i]= np.random.randint(1,3)\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,2)\n",
    "        \n",
    "    #     novel        \n",
    "    d['f_n'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "    d['f_c'] = d['f_h'] +d ['f_n']\n",
    "    \n",
    "    # convert signals to indicators\n",
    "    for j,letter in enumerate(['p','h','n']):\n",
    "        for i in np.arange(d['f_c'].shape[0]):\n",
    "            if   d['f_%s'%letter][i]==2: d['z_%s'%letter][i]=1\n",
    "            elif d['f_%s'%letter][i]==1: d['y_%s'%letter][i]=1\n",
    "            \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params['lambda_%s'%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap = generate_haploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['f_p', 'f_h', 'f_n', 'f_c', 'A_p', 'mu_p', 'var_p', 's_p', 'A_c', 'mu_c', 'var_c', 's_c'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,letter in enumerate(['p','h','n']):\n",
    "    print('f_%s: \\n'%letter,np.transpose(d['f_%s'%letter]))\n",
    "    print('z_%s: \\n'%letter,np.transpose(d['z_%s'%letter]))\n",
    "    print('y_%s: \\n'%letter,np.transpose(d['y_%s'%letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = generate_diploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['f_p2', 'f_c', 'f_p', 'z_p', 'y_p', 'f_h', 'z_h', 'y_h', 'f_n', 'z_n', 'y_n', 'A_p', 'mu_p', 'var_p', 's_p', 'A_c', 'mu_c', 'var_c', 's_c'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(data1['f_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 2, 0, 8, 0, 1, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        3, 1, 0, 0, 0, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 0, 1, 1, 2, 1, 0, 1,\n",
       "        1, 1, 2, 1, 2, 0, 2, 0, 0, 3, 2, 1, 0, 0, 1, 2, 0, 3, 0, 1, 0, 0,\n",
       "        2, 2, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 3, 1, 0, 1, 0, 1, 4, 0,\n",
       "        3, 2, 4, 2, 0, 0, 0, 3, 1, 0, 3, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -2, -1, -2,  0, -1,  2,  0,  0, -4,  0,  2, -2,  0, -2,  0,\n",
       "         1, -1,  0,  0, -1,  0, -2, -1,  0,  0,  0, -2,  0, -3,  0,  0,\n",
       "        -2,  0,  0, -2,  0, -1, -2, -1,  0,  0,  0, -2,  2, -1, -2, -1,\n",
       "        -1,  2,  0, -3, -1,  0, -1,  0,  0,  0,  0,  0, -2,  1,  1, -1,\n",
       "         0, -1, -1,  0,  0,  0, -1, -1, -2, -2, -1, -2, -1, -1, -1,  0,\n",
       "         0, -1,  1,  0,  2, -1, -1, -1, -1,  0,  0,  0, -1, -2,  2,  0,\n",
       "        -2, -2,  0,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(data1['f_p'] - data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
