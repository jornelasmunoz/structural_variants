{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e9ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Show matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f5ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "desktop_path = '/Users/jocelynornelasmunoz/Desktop/Research/structural_variants/'\n",
    "laptop_path = '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/structural_variants/'\n",
    "if desktop_path + 'lib/' not in sys.path: sys.path.insert(0, desktop_path + 'lib/')\n",
    "elif laptop_path + 'lib/' not in sys.path: sys.path.insert(0, laptop_path + 'lib/')\n",
    "import generate_data as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "import sympy\n",
    "import random\n",
    "# MATLAB\n",
    "# import matlab.engine\n",
    "# import matlab\n",
    "# print(matlab.__file__)\n",
    "# eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad47293",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate data and save to `.mat` file\n",
    "1. Define the set of parameters\n",
    "2. Generate diploid data\n",
    "3. Save to `.mat` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a208a2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 4,\n",
    "    'pctNovel': 0.2,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.5}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8bfee92-b6b1-4f08-a753-0b274194651a",
   "metadata": {},
   "source": [
    "data_path = (desktop_path+'%ip_%ic_coverage/')%(params['lambda_p'],params['lambda_c'])\n",
    "if not os.path.exists(data_path): os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33f89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed 10 \n",
      "Generating data...\n",
      "Done!\n",
      "\n",
      "Using parameters:\n",
      "\t r :  1\n",
      "\t n :  100\n",
      "\t k :  10\n",
      "\t lambda_c :  4\n",
      "\t lambda_p :  4\n",
      "\t pctNovel :  0.2\n",
      "\t erreps :  0.01\n",
      "\t pct_similarity :  0.5\n",
      "CPU times: user 8.28 ms, sys: 3.19 ms, total: 11.5 ms\n",
      "Wall time: 10.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = gd.generate_diploid_data(params, seed=10)\n",
    "savemat((desktop_path + 'data/%ipctNovel_%ik_%in.mat')%(int(params['pctNovel']*100),params['k'],params['n']) , data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d674e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2da3373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(data['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c5b471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['f_c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8906b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Debug `generate_diploid_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7be49-6e42-4cba-b86a-b7dc2ea2aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prnt=True\n",
    "# First, we randomly permute a sequence (1,2,3,...n)\n",
    "q = np.random.permutation(np.arange(1,params['n']+1))\n",
    "\n",
    "\n",
    "startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "\n",
    "# Create signal variables and initialize signal vectors with all zeros\n",
    "signals = ['f_p2', 'f_c']\n",
    "for i,letter in enumerate(['p', 'h', 'n']):\n",
    "    signals.append('f_%s'%letter)\n",
    "    signals.append('z_%s'%letter)\n",
    "    signals.append('y_%s'%letter)\n",
    "\n",
    "d= {}\n",
    "for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "if prnt: print('Signals initialized: ', [key for key in d.keys()])\n",
    "\n",
    "# Parent signals: \n",
    "#        f_p  - k elements will be 1s and 2s randomly selected\n",
    "#        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "#               (i.e. the parents will only share a given percentage of SV's)\n",
    "\n",
    "# Insert k number of 1's and 2's in the first parent\n",
    "for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "\n",
    "# parent 2 shares similarity number of SV's with parent 1, \n",
    "# q[0:similarity] is the positions for which both parents will share SV's\n",
    "# the remaining k - similarity positions will be chosen randomly as to not overlap with existing SVs\n",
    "rand_choices = np.random.choice(np.setdiff1d(q, q[0:similarity]), size=params['k'] -similarity, replace= False); #rand_choices.sort(); q[0:similarity].sort()\n",
    "d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "d['f_p2'][rand_choices]= np.random.randint(1,3) \n",
    "\n",
    "# verify that both parents have the same amount of nonzero entries\n",
    "if np.count_nonzero(d['f_p2']) != np.count_nonzero(d['f_p']): \n",
    "    print('PARENTS DO NOT HAVE EQUAL AMOUNT OF NONZERO ENTRIES !!')\n",
    "    print('f_p: {} \\nf_p2: {}'.format(np.count_nonzero(d['f_p']),np.count_nonzero(d['f_p2'])))\n",
    "\n",
    "\n",
    "# Child signal\n",
    "#     First, we defined the inherited SVs through a logical implementation \n",
    "#     of inheritance using parent 1 (f_p) and parent 2 (f_p2)\n",
    "for i in np.arange(d['f_p'].shape[0]):\n",
    "    if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_h'][i]= 2\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,3)\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_h'][i]= 1\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_h'][i]= np.random.randint(1,3)\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,2)\n",
    "\n",
    "#    Next, we define the novel SVs \n",
    "#    define inherited indices and novel indices, make sure they do not overlap\n",
    "inherited_pos = d['f_h'].nonzero()[0]; inherited_pos.sort()\n",
    "novel_pos = np.random.choice(np.setdiff1d(q, inherited_pos), size=int(params['k'] *params['pctNovel']), replace= False)\n",
    "d['f_n'][novel_pos]= np.random.randint(1,3) \n",
    "\n",
    "#    Lastly, we define the complete child signal\n",
    "d['f_c'] = d['f_h'] + d['f_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a841f-b0cf-45ed-8485-c2cfa4d5e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions for which both parents will share SV's\n",
    "q[0:similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba69f76-339f-4805-9724-dfb84fdefcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent 2 shares similarity number of SV's with parent 1\n",
    "#d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "#d['f_p2'][q[0:similarity]]\n",
    "d['f_p2'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee519d-9898-4cb9-825d-05a21d8b577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_choices = np.random.choice(q, size=params['k'] -similarity, replace= False)\n",
    "rand_choices.sort()\n",
    "print(rand_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24f732-7605-461c-b92f-95a528b2a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(q[0:similarity]).sort()\n",
    "q[0:similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f61c62-3ca0-4699-bb4b-b985c177f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0:similarity] == rand_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f5398-db1d-444e-8182-cfca792ce2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(q[0:similarity]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99750fc7-bea7-46cd-b878-850d8f4b758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in q[0:similarity]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d6c34-7545-4c49-a5e5-34d6b5c46929",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(q[0:similarity]): print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab246349-5a22-4d85-8abc-038fb2336d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to make sure similarity positions are not overwritten in parent 2\n",
    "# \n",
    "for i, val in enumerate(q[0:similarity]): \n",
    "    if val not in rand_choices:\n",
    "        pass \n",
    "        print('good: ', val)\n",
    "    else: \n",
    "        rand_choices[i] = np.random.choice(q) \n",
    "        print('position now: ', rand_choices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1060fe-78c9-4be4-9415-eba5b16936e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['f_p2'][rand_choices]= np.random.randint(1,3) \n",
    "d['f_p2'][rand_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb21ce-8222-48bb-ac85-c70719165b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['f_p'][rand_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad4079-a6f9-477d-9359-900690678971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.count_nonzero(d['f_p2']) \n",
    "np.count_nonzero(d['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c90c3-0285-421a-904c-99b79b8a9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.count_nonzero(d['f_p2']) != np.count_nonzero(d['f_p']): \n",
    "    print('PARENTS DO NOT HAVE EQUAL AMOUNT OF NONZERO ENTRIES !!')\n",
    "    print('f_p: {} \\nf_p2: {}'.format(np.count_nonzero(d['f_p']),np.count_nonzero(d['f_p2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1df64a-73e8-4c75-ac64-100febb38580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(d['f_p'].shape[0]):\n",
    "    if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_h'][i]= 2\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,3)\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_h'][i]= 1\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_h'][i]= np.random.randint(1,3)\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,2)\n",
    "d['f_h'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a623618-919a-4594-b7a1-0841c9a64181",
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_pos = d['f_h'].nonzero()[0]; inherited_pos.sort()\n",
    "inherited_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd272136-a2de-4bf0-a5af-384d44b25e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_pos = np.random.choice(q, size=int(params['k'] *params['pctNovel']), replace= False); novel_pos.sort()\n",
    "novel_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeca4c7-7333-43eb-aae2-08656e3b74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_pos[np.where(inherited_pos == 27)[0]] = np.random.choice(q)\n",
    "inherited_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdca5ab-937c-4654-8e72-74e0e2fdae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_pos = np.array([15,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09272675-32ba-4f1f-bc34-ca6ec6f5f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(novel_pos):\n",
    "    if val not in inherited_pos:\n",
    "        pass \n",
    "        print(val, ' from novel not in inherited')\n",
    "    else: \n",
    "        novel_pos[i] = np.random.choice(q)\n",
    "        #inherited_pos[np.where(inherited_pos == val)[0]] = np.random.choice(q)\n",
    "        print('not good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c5841-ae26-4539-a147-cfb17cff627b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b68a5a-c4f8-426a-827d-879adf16d57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cbc4a-df9f-41d8-9bc0-2304f35cef04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7c71c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Defining generate data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd463d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_haploid_data(params):\n",
    "    '''\n",
    "    Generate simulated data for a one parent, one child Structural Variant analysis\n",
    "    Args: A dictionary containing the following parameters as keys\n",
    "        n: size of data vectors (signals)\n",
    "        k: total number of structural variants\n",
    "        pctNovel: percent of novel structural variants in [0,1] (biological reality- very small %)\n",
    "        lambda_p, lambda_c: sequence coverage of child and parent, respectively\n",
    "        erreps: error (>0) incurred by sequencing and mapping process\n",
    "        r: dispersion parameter for Negative Binomial distribution\n",
    "    \n",
    "    Output: A dictionary containing the following data elements as keys\n",
    "        A_c: (lambda_c - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        A_p: (lambda_p - erreps) I_n, sparse diagonal nxn matrix. I_n is nxn identity matrix\n",
    "        mu_p, var_p: Mean and variance sequence coverage for parent; mu_p = A_p * f_p \n",
    "        mu_c, var_c: Mean and variance sequence coverage for child;  mu_c = A_c * f_c \n",
    "        s_p: nx1 random vector drawn from Negative binomial distribution (for parent)\n",
    "        s_c: nx1 random vector drawn from Negative binomial distribution (for child)\n",
    "        TODO: add mu and var\n",
    "        for i in {P (parent), H (inherited), N (novel)}:\n",
    "        z_i: nx1 indicator vector of homogeneous structural variants\n",
    "        y_i: nx1 indicator vector of heterogeneous structural variants\n",
    "        \n",
    "    '''\n",
    "    q = np.random.permutation(params['n'])\n",
    "    #print(q)\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "\n",
    "    f_p, f_c, f_h, f_n = np.zeros((params['n'],1), dtype=np.int8),np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8), np.zeros((params['n'],1), dtype=np.int8)\n",
    "    f_p[q[: params['k']]], f_c[q[startVal:endVal]] = 1,1\n",
    "    f_h[q[startVal:params['k']+1]], f_n[q[params['k']+1:endVal]] = 1,1\n",
    "    \n",
    "    \n",
    "    d = {}\n",
    "    d['f_p'] = f_p; d['f_h'] = f_h; d['f_n'] = f_n; d['f_c'] = f_h + f_n; \n",
    "    \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params[\"lambda_%s\"%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ca9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**2,\n",
    "    'k': 10,\n",
    "    'lambda_c': 4,\n",
    "    'lambda_p': 8,\n",
    "    'pctNovel': 0.15,\n",
    "    'erreps'  : 1e-2,\n",
    "    #'suffix'  : ['p','c'],\n",
    "    'pct_similarity': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diploid_data(params):\n",
    "    q = np.random.permutation(params['n'])\n",
    "    startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "    endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "    similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "    signals = ['f_p2', 'f_c']\n",
    "    for i,letter in enumerate(['p', 'h', 'n']):\n",
    "        signals.append('f_%s'%letter)\n",
    "        signals.append('z_%s'%letter)\n",
    "        signals.append('y_%s'%letter)\n",
    "\n",
    "    # Initialize signals\n",
    "    d= {}\n",
    "    for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "\n",
    "    # parent signals: \n",
    "    #        f_p  - k elements will be 1s and 2s randomly selected\n",
    "    #        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "    for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "    d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "    d['f_p2'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "\n",
    "    # child signal\n",
    "    #     inherited\n",
    "    for i in np.arange(d['f_p'].shape[0]):\n",
    "        if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_c'][i]= 2\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,3)\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_c'][i]= 1\n",
    "        elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_c'][i]= np.random.randint(1,3)\n",
    "        elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_c'][i]= np.random.randint(0,2)\n",
    "        \n",
    "    #     novel        \n",
    "    d['f_n'][random.choices(q, k=params['k'] -similarity)]= np.random.randint(1,3) \n",
    "    d['f_c'] = d['f_h'] +d ['f_n']\n",
    "    \n",
    "    # convert signals to indicators\n",
    "    for j,letter in enumerate(['p','h','n']):\n",
    "        for i in np.arange(d['f_c'].shape[0]):\n",
    "            if   d['f_%s'%letter][i]==2: d['z_%s'%letter][i]=1\n",
    "            elif d['f_%s'%letter][i]==1: d['y_%s'%letter][i]=1\n",
    "            \n",
    "    for i, letter in enumerate(['p','c']):\n",
    "        d['A_%s'%letter]   = (params['lambda_%s'%letter] - params['erreps'])*sparse.eye(params['n'])\n",
    "        d['mu_%s'%letter]  = np.matmul(d['A_%s'%letter].toarray(), d['f_%s'%letter]) + params['erreps']\n",
    "        d['var_%s'%letter] = d['mu_%s'%letter] +(1/params['r'])*(d['mu_%s'%letter]**2)\n",
    "        d['s_%s'%letter]   = np.random.negative_binomial(d['mu_%s'%letter]/(d['var_%s'%letter]-d['mu_%s'%letter]),d['mu_%s'%letter]/d['var_%s'%letter])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37114f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap = generate_haploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff3a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,letter in enumerate(['p','h','n']):\n",
    "    print('f_%s: \\n'%letter,np.transpose(d['f_%s'%letter]))\n",
    "    print('z_%s: \\n'%letter,np.transpose(d['z_%s'%letter]))\n",
    "    print('y_%s: \\n'%letter,np.transpose(d['y_%s'%letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = generate_diploid_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cf4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(data1['f_p'] - data1['s_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f753a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
