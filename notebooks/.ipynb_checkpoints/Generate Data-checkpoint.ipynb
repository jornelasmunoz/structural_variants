{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45338074",
   "metadata": {},
   "source": [
    "# Generate SV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b1cc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Show matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d363903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path =  /Users/jocelynornelasmunoz/Desktop/Research/structural_variants/\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "import sympy\n",
    "import random\n",
    "\n",
    "desktop_path = '/Users/jocelynornelasmunoz/Desktop/Research/structural_variants/'\n",
    "laptop_path = '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/structural_variants/'\n",
    "if desktop_path in sys.path[0]: sys.path.insert(0, desktop_path + 'lib/pyfiles'); path = desktop_path\n",
    "elif laptop_path in sys.path[0]: sys.path.insert(0, laptop_path + 'lib/pyfiles'); path = laptop_path\n",
    "print('Using path = ', path)\n",
    "import generate_data as gd\n",
    "\n",
    "# MATLAB\n",
    "# import matlab.engine\n",
    "# import matlab\n",
    "# print(matlab.__file__)\n",
    "# eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191e372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate data and save to `.mat` file\n",
    "1. Define the set of parameters\n",
    "2. Generate diploid data\n",
    "3. Save to `.mat` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646356d9",
   "metadata": {},
   "source": [
    "On his thesis, Andrew used $n = 10^6$ and $k=500$.  \n",
    "This means of $10^6$ positions, $0.05%$ of those are Structural Variants. So let's try to keep that percentage??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518659a7",
   "metadata": {},
   "source": [
    "## Define parameters to make simulated data\n",
    "| Parameter     | Description | \n",
    "| -----------    | ------------- |\n",
    "| r             |  dispersion parameter of negative binomial distribution.   Standard deviation is maximized when r=1. |\n",
    "|n              | number of candidate SV locations |\n",
    "|k              | total number of SVs  |\n",
    "|lambda_c       | child's sequencing coverage |\n",
    "|lambda_p       | parent's sequencing coverage|\n",
    "|pctNovel       | percent of novel structural variants in [0,1] (biological reality- very small %) |\n",
    "|erreps         |error (>0) incurred by sequencing and mapping process|\n",
    "|pct_similarity | percent similarity of SVs between parents |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fae8882a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define parameters to make data\n",
    "params = {\n",
    "    'r': 1,\n",
    "    'n': 10**5,\n",
    "    'k': 5000,\n",
    "    'lambda_p': 7,\n",
    "    'lambda_c': 3,\n",
    "    'pctNovel': 0.04,\n",
    "    'erreps'  : 1e-1,\n",
    "    'pct_similarity': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cebd74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed 10 \n",
      "Generating data...\n",
      "similarity 4000\n",
      "rand choices 1000\n",
      "combined 5000\n",
      "inherited pos length 4329\n",
      "novel pos length 200\n",
      "novel unique  [0 1 2]\n",
      "Done!\n",
      "\n",
      "Using parameters:\n",
      "\t r :  1\n",
      "\t n :  100000\n",
      "\t k :  5000\n",
      "\t lambda_p :  7\n",
      "\t lambda_c :  3\n",
      "\t pctNovel :  0.04\n",
      "\t erreps :  0.01\n",
      "\t pct_similarity :  0.8\n",
      "CPU times: user 59.1 s, sys: 1min 38s, total: 2min 38s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Paths for simulated data\n",
    "save_path = (path + 'data/%in_%ik/%iLp_%iLc/')%(params['n'], params['k'], params['lambda_p'], params['lambda_c'])\n",
    "filename = 'diploid_{}pctNovel_{}pctSim_{:.0e}eps.mat'.format(int(params['pctNovel']*100), int(params['pct_similarity']*100), params['erreps'])\n",
    "\n",
    "# generate data\n",
    "# create directory if non-existent\n",
    "if not os.path.exists(save_path): os.makedirs(save_path)\n",
    "data = gd.generate_diploid_data(params, seed=10, filepath=None)#os.path.join(save_path,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f97d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generate haploid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ba0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = gd.generate_haploid_data(params, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = 'haploid'\n",
    "outpath = (path + 'data/%s_%ipctNovel_%ik_%in.mat')%(kind,int(params['pctNovel']*100),params['k'],params['n'])\n",
    "savemat(outpath, data)\n",
    "print(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a703a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Look at generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1225a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows what variables will be saved\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nonzero counts for vector signals')\n",
    "\n",
    "print('f_p: ',np.count_nonzero(data['f_p']))\n",
    "print('f_c: ',np.count_nonzero(data['f_c']))\n",
    "print('f_h: ',np.count_nonzero(data['f_h']))\n",
    "print('f_n: ',np.count_nonzero(data['f_n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629469ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of mean and variance of TRUE data\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\n",
    "stacked_mu  = np.reshape(np.stack((data['mu_c'], data['mu_p']), axis=1), (data['mu_c'].shape[0],2))\n",
    "stacked_var = np.reshape(np.stack((data['var_c'], data['var_p']), axis=1), (data['var_c'].shape[0],2))\n",
    "stacked_p = np.reshape(np.stack((data['f_p'], data['s_p']), axis=1), (data['f_p'].shape[0],2))\n",
    "stacked_c = np.reshape(np.stack((data['f_c'], data['s_c']), axis=1), (data['f_c'].shape[0],2))\n",
    "\n",
    "colors = ['blue', 'orange']\n",
    "ax0.hist(stacked_mu, 10, density=True, histtype='bar', color=colors, label=['mu_c = %s'%str(4), 'mu_p = %s'%str(4)])\n",
    "ax0.legend(prop={'size': 10})\n",
    "ax0.set_title('Average coverage: mu')\n",
    "ax0.set_xlabel('mu values')\n",
    "#ax0.set_xlim([0, 5]); ax0.set_ylim([0, 2.5])\n",
    "\n",
    "ax1.hist(stacked_var, 10, density=True, histtype='bar', color=colors, label=['var_c', 'var_p'])\n",
    "ax1.legend(prop={'size': 10})\n",
    "ax1.set_title('Variance in coverage: var')\n",
    "ax1.set_xlabel('var values')\n",
    "#ax1.set_xlim([0, 5]); ax1.set_ylim([0, 2.5])\n",
    "\n",
    "ax2.hist(stacked_p, 10, density=True, histtype='bar', color=['orange','wheat'], label=['truth', 'obs'])\n",
    "ax2.legend(prop={'size': 10})\n",
    "ax2.set_title('Parent signal')\n",
    "\n",
    "ax3.hist(stacked_c, 10, density=True, histtype='bar', color=['dodgerblue','lightsteelblue'], label=['truth', 'obs'])\n",
    "ax3.legend(prop={'size': 10})\n",
    "ax3.set_title('Child signal')\n",
    "\n",
    "fig.set_size_inches(15, 10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prnt=True\n",
    "# First, we randomly permute a sequence (1,2,3,...n)\n",
    "q = np.random.permutation(np.arange(1,params['n']+1))\n",
    "\n",
    "\n",
    "startVal = int(params['k']*params['pctNovel']); #print(startVal)\n",
    "endVal = int(startVal +params['k']) ; #print(endVal)\n",
    "similarity = int(params['pct_similarity']* params['k']) # pct_similarity * number of SVs\n",
    "\n",
    "\n",
    "# Create signal variables and initialize signal vectors with all zeros\n",
    "signals = ['f_p2', 'f_c']\n",
    "for i,letter in enumerate(['p', 'h', 'n']):\n",
    "    signals.append('f_%s'%letter)\n",
    "    signals.append('z_%s'%letter)\n",
    "    signals.append('y_%s'%letter)\n",
    "\n",
    "d= {}\n",
    "for signal in signals: d[signal] = np.zeros((params['n'],1), dtype=np.int32)\n",
    "if prnt: print('Signals initialized: ', [key for key in d.keys()])\n",
    "\n",
    "# Parent signals: \n",
    "#        f_p  - k elements will be 1s and 2s randomly selected\n",
    "#        f_p2 - floor of %similarity*k elements will be the same as f_p and the rest will be random 1s and 2s\n",
    "#               (i.e. the parents will only share a given percentage of SV's)\n",
    "\n",
    "# Insert k number of 1's and 2's in the first parent\n",
    "for i in q[:params['k']]: d['f_p'][i] = np.random.randint(1,3) \n",
    "\n",
    "# parent 2 shares similarity number of SV's with parent 1, \n",
    "# q[0:similarity] is the positions for which both parents will share SV's\n",
    "# the remaining k - similarity positions will be chosen randomly as to not overlap with existing SVs\n",
    "rand_choices = np.random.choice(np.setdiff1d(q, q[0:similarity]), size=params['k'] -similarity, replace= False); #rand_choices.sort(); q[0:similarity].sort()\n",
    "d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "d['f_p2'][rand_choices]= np.random.randint(1,3) \n",
    "\n",
    "# verify that both parents have the same amount of nonzero entries\n",
    "if np.count_nonzero(d['f_p2']) != np.count_nonzero(d['f_p']): \n",
    "    print('PARENTS DO NOT HAVE EQUAL AMOUNT OF NONZERO ENTRIES !!')\n",
    "    print('f_p: {} \\nf_p2: {}'.format(np.count_nonzero(d['f_p']),np.count_nonzero(d['f_p2'])))\n",
    "\n",
    "\n",
    "# Child signal\n",
    "#     First, we defined the inherited SVs through a logical implementation \n",
    "#     of inheritance using parent 1 (f_p) and parent 2 (f_p2)\n",
    "for i in np.arange(d['f_p'].shape[0]):\n",
    "    if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_h'][i]= 2\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,3)\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_h'][i]= 1\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_h'][i]= np.random.randint(1,3)\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,2)\n",
    "\n",
    "#    Next, we define the novel SVs \n",
    "#    define inherited indices and novel indices, make sure they do not overlap\n",
    "inherited_pos = d['f_h'].nonzero()[0]; inherited_pos.sort()\n",
    "novel_pos = np.random.choice(np.setdiff1d(q, inherited_pos), size=int(params['k'] *params['pctNovel']), replace= False)\n",
    "d['f_n'][novel_pos]= np.random.randint(1,3) \n",
    "\n",
    "#    Lastly, we define the complete child signal\n",
    "d['f_c'] = d['f_h'] + d['f_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions for which both parents will share SV's\n",
    "q[0:similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca920946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent 2 shares similarity number of SV's with parent 1\n",
    "#d['f_p2'][q[0:similarity]] = d['f_p'][q[0:similarity]]\n",
    "#d['f_p2'][q[0:similarity]]\n",
    "d['f_p2'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728468f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_choices = np.random.choice(q, size=params['k'] -similarity, replace= False)\n",
    "rand_choices.sort()\n",
    "print(rand_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041777cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(q[0:similarity]).sort()\n",
    "q[0:similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd702d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[0:similarity] == rand_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b77727",
   "metadata": {},
   "outputs": [],
   "source": [
    "(q[0:similarity]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in q[0:similarity]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(q[0:similarity]): print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e05db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to make sure similarity positions are not overwritten in parent 2\n",
    "# \n",
    "for i, val in enumerate(q[0:similarity]): \n",
    "    if val not in rand_choices:\n",
    "        pass \n",
    "        print('good: ', val)\n",
    "    else: \n",
    "        rand_choices[i] = np.random.choice(q) \n",
    "        print('position now: ', rand_choices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['f_p2'][rand_choices]= np.random.randint(1,3) \n",
    "d['f_p2'][rand_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['f_p'][rand_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.count_nonzero(d['f_p2']) \n",
    "np.count_nonzero(d['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.count_nonzero(d['f_p2']) != np.count_nonzero(d['f_p']): \n",
    "    print('PARENTS DO NOT HAVE EQUAL AMOUNT OF NONZERO ENTRIES !!')\n",
    "    print('f_p: {} \\nf_p2: {}'.format(np.count_nonzero(d['f_p']),np.count_nonzero(d['f_p2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(d['f_p'].shape[0]):\n",
    "    if   (d['f_p'][i]==2 and d['f_p2'][i]==2): d['f_h'][i]= 2\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,3)\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==2): d['f_h'][i]= 1\n",
    "    elif (d['f_p'][i]==2 and d['f_p2'][i]==1) or (d['f_p'][i]==1 and d['f_p2'][i]==2): d['f_h'][i]= np.random.randint(1,3)\n",
    "    elif (d['f_p'][i]==1 and d['f_p2'][i]==0) or (d['f_p'][i]==0 and d['f_p2'][i]==1): d['f_h'][i]= np.random.randint(0,2)\n",
    "d['f_h'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68754422",
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_pos = d['f_h'].nonzero()[0]; inherited_pos.sort()\n",
    "inherited_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_pos = np.random.choice(q, size=int(params['k'] *params['pctNovel']), replace= False); novel_pos.sort()\n",
    "novel_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb16cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inherited_pos[np.where(inherited_pos == 27)[0]] = np.random.choice(q)\n",
    "inherited_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_pos = np.array([15,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(novel_pos):\n",
    "    if val not in inherited_pos:\n",
    "        pass \n",
    "        print(val, ' from novel not in inherited')\n",
    "    else: \n",
    "        novel_pos[i] = np.random.choice(q)\n",
    "        #inherited_pos[np.where(inherited_pos == val)[0]] = np.random.choice(q)\n",
    "        print('not good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0bc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43187b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cf0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09560a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(d['f_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0465a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(data['mu_c'][data['mu_c'] == 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a343f0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Andrew's data to visualize (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da914a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat(path + 'lib/old/neg_binom_nov_p4_c4_20perNov.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d356516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of mean and variance of TRUE data\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\n",
    "stacked_mu  = np.reshape(np.stack((data['mu_c'], mat['mu_c']), axis=1), (data['mu_c'].shape[0],2))\n",
    "stacked_var = np.reshape(np.stack((data['var_c'], mat['var_c']), axis=1), (data['var_c'].shape[0],2))\n",
    "stacked_p = np.reshape(np.stack((data['f_p'], data['s_p'],mat['y_p_neg_binom']), axis=1), (data['f_p'].shape[0],3))\n",
    "stacked_c = np.reshape(np.stack((data['f_c'], data['s_c'],mat['y_c_neg_binom']), axis=1), (data['f_c'].shape[0],3))\n",
    "\n",
    "colors = ['blue', 'orange']\n",
    "legend1 = ['Python mu_c = %s'%str(4), 'MATLAB mu_c = %s'%str(4)]\n",
    "ax0.hist(stacked_mu, 5, density=False, histtype='bar', color=colors, label=legend1)\n",
    "ax0.legend(prop={'size': 10})\n",
    "ax0.set_title('Average coverage: mu')\n",
    "ax0.set_xlabel('mu values')\n",
    "ax0.set_ylabel('counts')\n",
    "#ax0.set_xlim([0, 5]); ax0.set_ylim([0, 2.5])\n",
    "#ax0.set_yscale('log')\n",
    "\n",
    "label2 = ['Python var_c', 'MATLAB var_c']\n",
    "ax1.hist(stacked_var, 5, density=False, histtype='bar', color=colors, label=label2)\n",
    "ax1.legend(prop={'size': 10})\n",
    "ax1.set_title('Variance in coverage: var')\n",
    "ax1.set_xlabel('var values')\n",
    "ax1.set_ylabel('counts')\n",
    "#ax1.set_xlim([0, 5]); ax1.set_ylim([0, 2.5])\n",
    "\n",
    "colors2 = ['forestgreen','orange','wheat']\n",
    "labels_signal = ['Truth','Python obs', 'MATLAB obs']\n",
    "ax2.hist(stacked_p, 10, density=False, histtype='bar', color=colors2, label=labels_signal)\n",
    "ax2.legend(prop={'size': 10})\n",
    "ax2.set_title('Parent signal')\n",
    "ax2.set_xlabel('signal values')\n",
    "ax2.set_ylabel('counts')\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "colors3 = ['forestgreen','dodgerblue','lightsteelblue']\n",
    "ax3.hist(stacked_c, 15, density=False, histtype='bar', color=colors3, label=labels_signal)\n",
    "ax3.legend(prop={'size': 10})\n",
    "ax3.set_title('Child signal')\n",
    "ax3.set_xlabel('signal values')\n",
    "ax3.set_ylabel('counts')\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "fig.set_size_inches(15, 10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bed8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
